{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0 0.04\n",
      "100 0.84\n",
      "200 0.84\n",
      "300 0.98\n",
      "400 0.94\n",
      "500 0.96\n",
      "600 0.96\n",
      "700 0.94\n",
      "800 0.98\n",
      "900 0.94\n",
      "1000 0.98\n",
      "1100 0.94\n",
      "1200 0.98\n",
      "1300 0.98\n",
      "1400 0.9\n",
      "1500 1.0\n",
      "1600 0.98\n",
      "1700 0.94\n",
      "1800 0.98\n",
      "1900 1.0\n",
      "2000 1.0\n",
      "2100 0.98\n",
      "2200 1.0\n",
      "2300 0.98\n",
      "2400 0.96\n",
      "2500 0.98\n",
      "2600 1.0\n",
      "2700 1.0\n",
      "2800 1.0\n",
      "2900 1.0\n",
      "3000 1.0\n",
      "3100 0.96\n",
      "3200 0.98\n",
      "3300 1.0\n",
      "3400 0.98\n",
      "3500 1.0\n",
      "3600 0.98\n",
      "3700 1.0\n",
      "3800 1.0\n",
      "3900 0.96\n",
      "4000 1.0\n",
      "4100 0.98\n",
      "4200 1.0\n",
      "4300 0.98\n",
      "4400 1.0\n",
      "4500 1.0\n",
      "4600 0.94\n",
      "4700 0.98\n",
      "4800 0.98\n",
      "4900 1.0\n",
      "5000 1.0\n",
      "5100 1.0\n",
      "5200 1.0\n",
      "5300 1.0\n",
      "5400 1.0\n",
      "5500 0.96\n",
      "5600 1.0\n",
      "5700 0.98\n",
      "5800 1.0\n",
      "5900 0.96\n",
      "6000 0.98\n",
      "6100 1.0\n",
      "6200 1.0\n",
      "6300 1.0\n",
      "6400 0.96\n",
      "6500 0.98\n",
      "6600 1.0\n",
      "6700 0.98\n",
      "6800 0.98\n",
      "6900 0.98\n",
      "7000 1.0\n",
      "7100 1.0\n",
      "7200 0.98\n",
      "7300 1.0\n",
      "7400 1.0\n",
      "7500 1.0\n",
      "7600 1.0\n",
      "7700 1.0\n",
      "7800 1.0\n",
      "7900 0.98\n",
      "8000 0.98\n",
      "8100 0.98\n",
      "8200 1.0\n",
      "8300 1.0\n",
      "8400 1.0\n",
      "8500 1.0\n",
      "8600 0.98\n",
      "8700 1.0\n",
      "8800 1.0\n",
      "8900 1.0\n",
      "9000 1.0\n",
      "9100 1.0\n",
      "9200 1.0\n",
      "9300 0.98\n",
      "9400 1.0\n",
      "9500 0.98\n",
      "9600 1.0\n",
      "9700 1.0\n",
      "9800 1.0\n",
      "9900 1.0\n",
      "10000 0.98\n",
      "10100 1.0\n",
      "10200 1.0\n",
      "10300 1.0\n",
      "10400 1.0\n",
      "10500 1.0\n",
      "10600 1.0\n",
      "10700 1.0\n",
      "10800 1.0\n",
      "10900 0.96\n",
      "11000 1.0\n",
      "11100 1.0\n",
      "11200 1.0\n",
      "11300 1.0\n",
      "11400 1.0\n",
      "11500 1.0\n",
      "11600 1.0\n",
      "11700 1.0\n",
      "11800 1.0\n",
      "11900 0.98\n",
      "12000 1.0\n",
      "12100 1.0\n",
      "12200 1.0\n",
      "12300 1.0\n",
      "12400 1.0\n",
      "12500 1.0\n",
      "12600 1.0\n",
      "12700 1.0\n",
      "12800 1.0\n",
      "12900 1.0\n",
      "13000 1.0\n",
      "13100 1.0\n",
      "13200 1.0\n",
      "13300 1.0\n",
      "13400 1.0\n",
      "13500 1.0\n",
      "13600 1.0\n",
      "13700 1.0\n",
      "13800 1.0\n",
      "13900 1.0\n",
      "14000 1.0\n",
      "14100 1.0\n",
      "14200 1.0\n",
      "14300 1.0\n",
      "14400 1.0\n",
      "14500 1.0\n",
      "14600 1.0\n",
      "14700 1.0\n",
      "14800 1.0\n",
      "14900 1.0\n",
      "15000 1.0\n",
      "15100 1.0\n",
      "15200 1.0\n",
      "15300 1.0\n",
      "15400 1.0\n",
      "15500 0.98\n",
      "15600 1.0\n",
      "15700 1.0\n",
      "15800 1.0\n",
      "15900 1.0\n",
      "16000 1.0\n",
      "16100 0.98\n",
      "16200 1.0\n",
      "16300 1.0\n",
      "16400 1.0\n",
      "16500 1.0\n",
      "16600 1.0\n",
      "16700 1.0\n",
      "16800 1.0\n",
      "16900 1.0\n",
      "17000 1.0\n",
      "17100 1.0\n",
      "17200 1.0\n",
      "17300 1.0\n",
      "17400 1.0\n",
      "17500 1.0\n",
      "17600 1.0\n",
      "17700 1.0\n",
      "17800 0.98\n",
      "17900 1.0\n",
      "18000 1.0\n",
      "18100 1.0\n",
      "18200 1.0\n",
      "18300 1.0\n",
      "18400 1.0\n",
      "18500 1.0\n",
      "18600 1.0\n",
      "18700 1.0\n",
      "18800 1.0\n",
      "18900 1.0\n",
      "19000 1.0\n",
      "19100 1.0\n",
      "19200 1.0\n",
      "19300 1.0\n",
      "19400 1.0\n",
      "19500 1.0\n",
      "19600 1.0\n",
      "19700 1.0\n",
      "19800 1.0\n",
      "19900 1.0\n",
      "0.9917\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# define parameters\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial=tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial_value=initial)\n",
    "def bias_variable(shape):\n",
    "    initial=tf.constant(value=0.1,shape=shape)\n",
    "    return tf.Variable(initial_value=initial)\n",
    "\n",
    "# define placeholders\n",
    "\n",
    "x=tf.placeholder(dtype=tf.float32, shape=[None,784])\n",
    "y=tf.placeholder(dtype=tf.float32, shape=[None,10])\n",
    "\n",
    "# reshape x\n",
    "\n",
    "x_res=tf.reshape(x, shape=[-1,28,28,1])\n",
    "\n",
    "# define convolution and pooling functions\n",
    "\n",
    "def conv(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=\"SAME\")\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "# create the first convolution layer and pooling\n",
    "\n",
    "w_conv1=weight_variable([5,5,1,32])\n",
    "b_conv1=bias_variable([32])\n",
    "\n",
    "conv1=tf.nn.relu(conv(x_res,w_conv1)+b_conv1)\n",
    "max_pool1=max_pool(conv1)\n",
    "\n",
    "# 14*14 image\n",
    "# create the second convolution and pooling layers\n",
    "\n",
    "w_conv2=weight_variable([5,5,32,64])\n",
    "b_conv2=bias_variable([64])\n",
    "\n",
    "conv2=tf.nn.relu(conv(max_pool1,w_conv2)+b_conv2)\n",
    "max_pool2=max_pool(conv2)\n",
    "\n",
    "# 7*7 image\n",
    "# create full-connection layer\n",
    "\n",
    "w_full=weight_variable([7*7*64, 1024])\n",
    "b_full=bias_variable([1024])\n",
    "\n",
    "x_full=tf.reshape(max_pool2, shape=[-1,7*7*64])\n",
    "function_full_connection=tf.nn.relu(tf.matmul(x_full, w_full)+b_full)\n",
    "\n",
    "# create dropout\n",
    "\n",
    "keep_drop=tf.placeholder(dtype=tf.float32)\n",
    "drop_out=tf.nn.dropout(function_full_connection, keep_drop)\n",
    "\n",
    "# output layer\n",
    "\n",
    "w_output=weight_variable([1024,10])\n",
    "b_output=bias_variable([10])\n",
    "\n",
    "y_output=tf.matmul(drop_out,w_output)+b_output\n",
    "\n",
    "# define loss function\n",
    "\n",
    "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=y_output))\n",
    "\n",
    "# define optimizer\n",
    "\n",
    "optimizer=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "# create correct_prediction and accuracy\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(y_output,1), tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Á‡ÔÛÒÍ ÒÂÒÒËË\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for each in range(20000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if each%100==0:\n",
    "            train_accuracy=sess.run(accuracy, feed_dict={x: batch[0],y: batch[1], keep_drop: 1.0})\n",
    "            print(each, train_accuracy)\n",
    "        sess.run(optimizer, feed_dict={x: batch[0], y: batch[1], keep_drop: 0.5})\n",
    "    test_accuracy=sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels, keep_drop: 1.0})\n",
    "    print(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
