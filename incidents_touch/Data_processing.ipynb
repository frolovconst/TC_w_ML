{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_path = '../data/PeMS/Incidents/raw'\n",
    "dest_path = '../data/PeMS/Incidents/light'\n",
    "pth = Path(raw_path)\n",
    "for child in pth.iterdir():\n",
    "    # incidents data reading\n",
    "    incdnt_file_name = child.name\n",
    "    inc_header = ['IncidentID', 'CC_Code', 'Incident_No', 'Timestamp', 'Description', 'Location', 'Area', 'Zoom_Map', 'TBxy', 'Latitude', 'Longitude', 'District', 'CountryFIPS_ID', 'CityFIPS_ID', 'Freeway', 'Freeway_direction', 'State_postmile', 'Absolute_postmile', 'Severity', 'Duration', 'Incident_ID', 'Detail_ID', 'Timestamp', 'description']\n",
    "    data_inc_d07 = pd.read_csv(raw_path+'/'+incdnt_file_name, sep=',', names=inc_header, parse_dates=[3])\n",
    "    data_inc_d07 = (data_inc_d07.dropna(subset=['District']))[data_inc_d07.columns[:-4]]\n",
    "    data_inc_d07 = data_inc_d07.astype(dtype={'District':int})\n",
    "    # result: incidents in district under analysis\n",
    "    data_inc_d07 = data_inc_d07[data_inc_d07['District']==7].reset_index(drop=True)\n",
    "    data_inc_d07.to_csv(dest_path+'/'+child.name[:-4]+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# incidents data reading\n",
    "incdnt_file_name = '../data/PeMS/Incidents/raw/all_text_chp_incident_day_2017_03_06.txt.gz'\n",
    "inc_header = ['IncidentID', 'CC_Code', 'Incident_No', 'Timestamp', 'Description', 'Location', 'Area', 'Zoom_Map', 'TBxy', 'Latitude', 'Longitude', 'District', 'CountryFIPS_ID', 'CityFIPS_ID', 'Freeway', 'Freeway_direction', 'State_postmile', 'Absolute_postmile', 'Severity', 'Duration', 'Incident_ID', 'Detail_ID', 'Timestamp', 'description']\n",
    "data_inc_d07 = pd.read_csv(incdnt_file_name, sep=',', names=inc_header, parse_dates=[3])\n",
    "data_inc_d07 = (data_inc_d07.dropna(subset=['District']))[data_inc_d07.columns[:-4]]\n",
    "data_inc_d07 = data_inc_d07.astype(dtype={'District':int})\n",
    "# result: incidents in district under analysis\n",
    "data_inc_d07 = data_inc_d07[data_inc_d07['District']==7].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_inc_d07.to_csv('../data/PeMS/Incidents/light/all_text_chp_incident_day_2017_03_06.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incidents details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incdnt_det_file_name = '../data/PeMS/Incidents/all_text_chp_incident_det_day_2017_10_11.txt'\n",
    "det_header = ['ID', 'DetID', 'Timestamp', 'Desc']\n",
    "data_inc_det_d07 = pd.read_csv(incdnt_det_file_name, sep=',', names=det_header, parse_dates=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_inc_det_d07.to_csv('../data/PeMS/Incidents/light/all_text_chp_incident_det_day_2017_10_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d07_text_station_5min_2017_05_28.txt.gz\n",
      "d07_text_station_5min_2017_05_24.txt.gz\n",
      "d07_text_station_5min_2017_05_30.txt.gz\n",
      "d07_text_station_5min_2017_05_27.txt.gz\n",
      "d07_text_station_5min_2017_05_12.txt.gz\n",
      "d07_text_station_5min_2017_05_23.txt.gz\n",
      "d07_text_station_5min_2017_05_31.txt.gz\n",
      "d07_text_station_5min_2017_05_14.txt.gz\n",
      "d07_text_station_5min_2017_05_29.txt.gz\n",
      "d07_text_station_5min_2017_05_04.txt.gz\n",
      "d07_text_station_5min_2017_05_06.txt.gz\n",
      "d07_text_station_5min_2017_05_16.txt.gz\n",
      "d07_text_station_5min_2017_05_19.txt.gz\n",
      "d07_text_station_5min_2017_05_01.txt.gz\n",
      "d07_text_station_5min_2017_05_07.txt.gz\n",
      "d07_text_station_5min_2017_05_22.txt.gz\n",
      "d07_text_station_5min_2017_05_21.txt.gz\n",
      "d07_text_station_5min_2017_05_03.txt.gz\n",
      "d07_text_station_5min_2017_05_18.txt.gz\n",
      "d07_text_station_5min_2017_05_08.txt.gz\n",
      "d07_text_station_5min_2017_05_26.txt.gz\n",
      "d07_text_station_5min_2017_05_13.txt.gz\n",
      "d07_text_station_5min_2017_05_11.txt.gz\n",
      "d07_text_station_5min_2017_05_02.txt.gz\n",
      "d07_text_station_5min_2017_05_17.txt.gz\n",
      "d07_text_station_5min_2017_05_05.txt.gz\n",
      "d07_text_station_5min_2017_05_09.txt.gz\n",
      "d07_text_station_5min_2017_05_25.txt.gz\n",
      "d07_text_station_5min_2017_05_10.txt.gz\n",
      "d07_text_station_5min_2017_05_15.txt.gz\n",
      "d07_text_station_5min_2017_05_20.txt.gz\n"
     ]
    }
   ],
   "source": [
    "raw_path = '../data/PeMS/Series/raw'\n",
    "raw_path = '/home/frolovconst/Dvlpt/prj/Python/tc_w_ml/data/PeMS/Series/Batch/2017/May/'\n",
    "dest_path = '../data/PeMS/Series/light'\n",
    "dest_path = '/home/frolovconst/Dvlpt/prj/Python/tc_w_ml/data/PeMS/Series/Batch/light/May'\n",
    "pth = Path(raw_path)\n",
    "st_blacklist = np.array([])\n",
    "header_srs = ['Timestamp', 'Station','District', 'Freeway', 'Direction of Travel', 'Lane Type', 'Station Length',\n",
    "          'Samples', '% Observed', 'Total Flow', 'Avg Occupancy', 'Avg Speed', \n",
    "          'Lane 1 Samples', 'Lane 1 Flow', 'Lane 1 Avg Occ', 'Lane 1 Avg Speed', 'Lane 1 Observed',\n",
    "          'Lane 2 Samples', 'Lane 2 Flow', 'Lane 2 Avg Occ', 'Lane 2 Avg Speed', 'Lane 2 Observed',\n",
    "          'Lane 3 Samples', 'Lane 3 Flow', 'Lane 3 Avg Occ', 'Lane 3 Avg Speed', 'Lane 3 Observed',\n",
    "          'Lane 4 Samples', 'Lane 4 Flow', 'Lane 4 Avg Occ', 'Lane 4 Avg Speed', 'Lane 4 Observed',\n",
    "          'Lane 5 Samples', 'Lane 5 Flow', 'Lane 5 Avg Occ', 'Lane 5 Avg Speed', 'Lane 5 Observed',\n",
    "          'Lane 6 Samples', 'Lane 6 Flow', 'Lane 6 Avg Occ', 'Lane 6 Avg Speed', 'Lane 6 Observed',\n",
    "          'Lane 7 Samples', 'Lane 7 Flow', 'Lane 7 Avg Occ', 'Lane 7 Avg Speed', 'Lane 7 Observed',\n",
    "          'Lane 8 Samples', 'Lane 8 Flow', 'Lane 8 Avg Occ', 'Lane 8 Avg Speed', 'Lane 8 Observed']\n",
    "for child in pth.iterdir():\n",
    "    # incidents data reading\n",
    "    srs_file_name = child.name\n",
    "#     if srs_file_name[0] !='p':\n",
    "#         continue\n",
    "    print(srs_file_name)\n",
    "\n",
    "    data_srs_smoothed = pd.read_csv(raw_path+'/'+srs_file_name, sep=',', names=header_srs, parse_dates=[0])\n",
    "\n",
    "    for col in data_srs_smoothed.columns[-40:]:\n",
    "        del data_srs_smoothed[col]\n",
    "    data_srs_smoothed.dropna(subset=['Avg Speed'], inplace=True)\n",
    "    data_srs_smoothed.to_csv(dest_path+'/'+child.name[:-4]+'.csv', index=False)\n",
    "    #smoothing\n",
    "#     data_srs_smoothed = data_srs_smoothed[data_srs_smoothed.columns[:16]]\n",
    "#     del data_srs_no_null\n",
    "\n",
    "    gb = data_srs_smoothed.groupby(by=['Station'])\n",
    "    j=0\n",
    "    for i, item in gb:\n",
    "    #     print(item['Avg Speed'].rolling(5).mean())\n",
    "    #     station = item.Station[0]\n",
    "        data_srs_smoothed.loc[item.index, ('Avg Speed')] = item['Avg Speed'].rolling(5).mean()\n",
    "    #     j += 1\n",
    "    #     if j==2:\n",
    "    #         break\n",
    "    data_srs_smoothed.dropna(subset=['Avg Speed'], inplace=True)\n",
    "\n",
    "#     del srs_for_smoothing_gb\n",
    "\n",
    "    gb = data_srs_smoothed.groupby(by=['Station'])\n",
    "    non_sensitive_sts = gb.filter(lambda x: (x['Avg Speed'].std()<1))['Station'].unique()\n",
    "    data_srs_smoothed = data_srs_smoothed[~data_srs_smoothed.Station.isin(non_sensitive_sts)]\n",
    "    data_srs_smoothed.to_csv(dest_path+'/smoothed/'+child.name[:-4]+'.csv', index=False)\n",
    "\n",
    "    data_srs_smoothed = None\n",
    "\n",
    "    st_blacklist = np.append(st_blacklist, non_sensitive_sts[~np.isin(non_sensitive_sts, st_blacklist)])\n",
    "    gb, non_sensitive_sts = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(dest_path+'/stations_blacklist_may.csv', st_blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d07_text_station_5min_2017_06_19.txt.gz\n",
      "d07_text_station_5min_2017_06_05.txt.gz\n",
      "d07_text_station_5min_2017_06_25.txt.gz\n",
      "d07_text_station_5min_2017_06_11.txt.gz\n",
      "d07_text_station_5min_2017_06_21.txt.gz\n",
      "d07_text_station_5min_2017_06_28.txt.gz\n",
      "d07_text_station_5min_2017_06_12.txt.gz\n",
      "d07_text_station_5min_2017_06_16.txt.gz\n",
      "d07_text_station_5min_2017_06_17.txt.gz\n",
      "d07_text_station_5min_2017_06_18.txt.gz\n",
      "d07_text_station_5min_2017_06_29.txt.gz\n",
      "d07_text_station_5min_2017_06_01.txt.gz\n",
      "d07_text_station_5min_2017_06_02.txt.gz\n",
      "d07_text_station_5min_2017_06_04.txt.gz\n",
      "d07_text_station_5min_2017_06_15.txt.gz\n",
      "d07_text_station_5min_2017_06_13.txt.gz\n",
      "d07_text_station_5min_2017_06_24.txt.gz\n",
      "d07_text_station_5min_2017_06_09.txt.gz\n",
      "d07_text_station_5min_2017_06_08.txt.gz\n",
      "d07_text_station_5min_2017_06_14.txt.gz\n",
      "d07_text_station_5min_2017_06_26.txt.gz\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ef242d567ce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrs_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdata_srs_smoothed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msrs_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_srs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_srs_smoothed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0mnew_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    273\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    274\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5504\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5506\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   4307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4309\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4310\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4311\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mform_blocks\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   4371\u001b[0m     \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4373\u001b[0;31m         \u001b[0mfloat_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multi_blockify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4374\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_multi_blockify\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   4448\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4450\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stack_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4452\u001b[0m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_stack_arrays\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   4491\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_shape_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4493\u001b[0;31m     \u001b[0mstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4494\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4495\u001b[0m         \u001b[0mstacked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raw_path = '../data/PeMS/Series/raw'\n",
    "raw_path = '/home/frolovconst/Dvlpt/prj/Python/tc_w_ml/data/PeMS/Series/Batch/2017/Jun/'\n",
    "dest_path = '../data/PeMS/Series/light'\n",
    "dest_path = '/home/frolovconst/Dvlpt/prj/Python/tc_w_ml/data/PeMS/Series/Batch/light/Jun'\n",
    "pth = Path(raw_path)\n",
    "st_blacklist = np.array([])\n",
    "header_srs = ['Timestamp', 'Station','District', 'Freeway', 'Direction of Travel', 'Lane Type', 'Station Length',\n",
    "          'Samples', '% Observed', 'Total Flow', 'Avg Occupancy', 'Avg Speed', \n",
    "          'Lane 1 Samples', 'Lane 1 Flow', 'Lane 1 Avg Occ', 'Lane 1 Avg Speed', 'Lane 1 Observed',\n",
    "          'Lane 2 Samples', 'Lane 2 Flow', 'Lane 2 Avg Occ', 'Lane 2 Avg Speed', 'Lane 2 Observed',\n",
    "          'Lane 3 Samples', 'Lane 3 Flow', 'Lane 3 Avg Occ', 'Lane 3 Avg Speed', 'Lane 3 Observed',\n",
    "          'Lane 4 Samples', 'Lane 4 Flow', 'Lane 4 Avg Occ', 'Lane 4 Avg Speed', 'Lane 4 Observed',\n",
    "          'Lane 5 Samples', 'Lane 5 Flow', 'Lane 5 Avg Occ', 'Lane 5 Avg Speed', 'Lane 5 Observed',\n",
    "          'Lane 6 Samples', 'Lane 6 Flow', 'Lane 6 Avg Occ', 'Lane 6 Avg Speed', 'Lane 6 Observed',\n",
    "          'Lane 7 Samples', 'Lane 7 Flow', 'Lane 7 Avg Occ', 'Lane 7 Avg Speed', 'Lane 7 Observed',\n",
    "          'Lane 8 Samples', 'Lane 8 Flow', 'Lane 8 Avg Occ', 'Lane 8 Avg Speed', 'Lane 8 Observed']\n",
    "for child in pth.iterdir():\n",
    "    # incidents data reading\n",
    "    srs_file_name = child.name\n",
    "#     if srs_file_name[0] !='p':\n",
    "#         continue\n",
    "    print(srs_file_name)\n",
    "\n",
    "    data_srs_smoothed = pd.read_csv(raw_path+'/'+srs_file_name, sep=',', names=header_srs, parse_dates=[0])\n",
    "\n",
    "    for col in data_srs_smoothed.columns[-40:]:\n",
    "        del data_srs_smoothed[col]\n",
    "    data_srs_smoothed.dropna(subset=['Avg Speed'], inplace=True)\n",
    "    data_srs_smoothed.to_csv(dest_path+'/'+child.name[:-4]+'.csv', index=False)\n",
    "    #smoothing\n",
    "#     data_srs_smoothed = data_srs_smoothed[data_srs_smoothed.columns[:16]]\n",
    "#     del data_srs_no_null\n",
    "\n",
    "    gb = data_srs_smoothed.groupby(by=['Station'])\n",
    "    j=0\n",
    "    for i, item in gb:\n",
    "    #     print(item['Avg Speed'].rolling(5).mean())\n",
    "    #     station = item.Station[0]\n",
    "        data_srs_smoothed.loc[item.index, ('Avg Speed')] = item['Avg Speed'].rolling(5).mean()\n",
    "    #     j += 1\n",
    "    #     if j==2:\n",
    "    #         break\n",
    "    data_srs_smoothed.dropna(subset=['Avg Speed'], inplace=True)\n",
    "\n",
    "#     del srs_for_smoothing_gb\n",
    "\n",
    "    gb = data_srs_smoothed.groupby(by=['Station'])\n",
    "    non_sensitive_sts = gb.filter(lambda x: (x['Avg Speed'].std()<1))['Station'].unique()\n",
    "    data_srs_smoothed = data_srs_smoothed[~data_srs_smoothed.Station.isin(non_sensitive_sts)]\n",
    "    data_srs_smoothed.to_csv(dest_path+'/smoothed/'+child.name[:-4]+'.csv', index=False)\n",
    "\n",
    "    data_srs_smoothed = None\n",
    "\n",
    "    st_blacklist = np.append(st_blacklist, non_sensitive_sts[~np.isin(non_sensitive_sts, st_blacklist)])\n",
    "    gb, non_sensitive_sts = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(dest_path+'/stations_blacklist_jun.csv', st_blacklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# traffic flow data reading\n",
    "header_srs = ['Timestamp', 'Station','District', 'Freeway', 'Direction of Travel', 'Lane Type', 'Station Length',\n",
    "          'Samples', '% Observed', 'Total Flow', 'Avg Occupancy', 'Avg Speed', \n",
    "          'Lane 1 Samples', 'Lane 1 Flow', 'Lane 1 Avg Occ', 'Lane 1 Avg Speed', 'Lane 1 Observed',\n",
    "          'Lane 2 Samples', 'Lane 2 Flow', 'Lane 2 Avg Occ', 'Lane 2 Avg Speed', 'Lane 2 Observed',\n",
    "          'Lane 3 Samples', 'Lane 3 Flow', 'Lane 3 Avg Occ', 'Lane 3 Avg Speed', 'Lane 3 Observed',\n",
    "          'Lane 4 Samples', 'Lane 4 Flow', 'Lane 4 Avg Occ', 'Lane 4 Avg Speed', 'Lane 4 Observed',\n",
    "          'Lane 5 Samples', 'Lane 5 Flow', 'Lane 5 Avg Occ', 'Lane 5 Avg Speed', 'Lane 5 Observed',\n",
    "          'Lane 6 Samples', 'Lane 6 Flow', 'Lane 6 Avg Occ', 'Lane 6 Avg Speed', 'Lane 6 Observed',\n",
    "          'Lane 7 Samples', 'Lane 7 Flow', 'Lane 7 Avg Occ', 'Lane 7 Avg Speed', 'Lane 7 Observed',\n",
    "          'Lane 8 Samples', 'Lane 8 Flow', 'Lane 8 Avg Occ', 'Lane 8 Avg Speed', 'Lane 8 Observed']\n",
    "\n",
    "srs_file_name = '../data/PeMS/Series/d07_text_station_5min_2017_10_11.txt'\n",
    "data_srs_no_null = pd.read_csv(srs_file_name, sep=',', names=header_srs, parse_dates=[0])\n",
    "data_srs_no_null = data_srs_no_null[data_srs_no_null.columns[:-40]]\n",
    "data_srs_no_null = data_srs_no_null.dropna(subset=['Avg Speed']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_srs_no_null.to_csv('../data/PeMS/Series/light/d07_text_station_5min_2017_10_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_srs_smoothed = data_srs_no_null[data_srs_no_null.columns[:16]].copy()\n",
    "srs_for_smoothing_gb = data_srs_smoothed.groupby(by=['Station'])\n",
    "j=0\n",
    "for i, item in srs_for_smoothing_gb:\n",
    "#     print(item['Avg Speed'].rolling(5).mean())\n",
    "#     station = item.Station[0]\n",
    "    data_srs_smoothed.loc[item.index, ('Avg Speed')] = item['Avg Speed'].rolling(5).mean()\n",
    "#     j += 1\n",
    "#     if j==2:\n",
    "#         break\n",
    "data_srs_smoothed = data_srs_smoothed.dropna(subset=['Avg Speed'])\n",
    "del srs_for_smoothing_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_srs_smoothed.to_csv('../data/PeMS/Series/smoothed/d07_text_station_5min_2017_10_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_stations = '../data/PeMS/Stations/d07_text_meta_2017_09_20.txt'\n",
    "header_stations = ['ID', 'Freeway', 'Freeway dir', 'Country', 'City', 'State Postmile', 'Abs Postmile', \n",
    "          'Latitude', 'Longitude', 'Length', 'Type', 'Lanes', 'Name',\n",
    "          'User ID1', 'User ID2', 'User ID3', 'User ID4']\n",
    "stations_active = pd.read_csv(file_stations, sep='\\t')\n",
    "stations_active = stations_active.astype({'Latitude':float, 'Longitude':float})\n",
    "stations_active = stations_active.dropna(subset=['Latitude', 'Longitude']).reset_index(drop=True)\n",
    "# result: non-empty speed data series  only, stations which provide these data\n",
    "stations_active = stations_active[stations_active['ID'].isin(data_srs_no_null['Station'].unique())].reset_index(drop=True)\n",
    "stations_active = stations_active.sort_values('Lanes', ascending=False).drop_duplicates(subset=['Latitude', 'Longitude'], keep='first').sort_index().reset_index(drop=True)\n",
    "stations_active = stations_active[~stations_active.ID.isin(st_blacklist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations_active.to_csv('../data/PeMS/Stations/light/d07_text_meta_2017_09_20_active.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# incidents week before data reading\n",
    "incdnt_file_name = '../data/PeMS/Incidents/all_text_chp_incident_day_2017_10_04.txt'\n",
    "data_inc_04_d07 = pd.read_csv(incdnt_file_name, sep=',', names=inc_header, parse_dates=[3])\n",
    "data_inc_04_d07 = (data_inc_04_d07.dropna(subset=['District']))[data_inc_04_d07.columns[:-4]]\n",
    "data_inc_04_d07 = data_inc_04_d07.astype(dtype={'District':int})\n",
    "# result: incidents in district under analysis\n",
    "data_inc_04_d07 = data_inc_04_d07[data_inc_04_d07['District']==7].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_inc_04_d07.to_csv('../data/PeMS/Incidents/light/all_text_chp_incident_day_2017_10_04.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# traffic week b4 flow data reading\n",
    "srs_file_name = '../data/PeMS/Series/d07_text_station_5min_2017_10_04.txt'\n",
    "data_srs_no_null_04 = pd.read_csv(srs_file_name, sep=',', names=header_srs, parse_dates=[0])\n",
    "data_srs_no_null_04 = data_srs_no_null_04[data_srs_no_null_04.columns[:-40]]\n",
    "# result: non-empty speed data series  only, stations which provide these data\n",
    "data_srs_no_null_04 = data_srs_no_null_04.dropna(subset=['Avg Speed']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_srs_no_null_04.to_csv('../data/PeMS/Series/light/d07_text_station_5min_2017_10_04.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
