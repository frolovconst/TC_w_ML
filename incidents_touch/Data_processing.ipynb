{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_path = '../data/PeMS/Incidents/raw'\n",
    "dest_path = '../data/PeMS/Incidents/script_test'\n",
    "pth = Path(raw_path)\n",
    "for child in pth.iterdir():\n",
    "    # incidents data reading\n",
    "    incdnt_file_name = child.name\n",
    "    inc_header = ['IncidentID', 'CC_Code', 'Incident_No', 'Timestamp', 'Description', 'Location', 'Area', 'Zoom_Map', 'TBxy', 'Latitude', 'Longitude', 'District', 'CountryFIPS_ID', 'CityFIPS_ID', 'Freeway', 'Freeway_direction', 'State_postmile', 'Absolute_postmile', 'Severity', 'Duration', 'Incident_ID', 'Detail_ID', 'Timestamp', 'description']\n",
    "    data_inc_d07 = pd.read_csv(raw_path+'/'+incdnt_file_name, sep=',', names=inc_header, parse_dates=[3])\n",
    "    data_inc_d07 = (data_inc_d07.dropna(subset=['District']))[data_inc_d07.columns[:-4]]\n",
    "    data_inc_d07 = data_inc_d07.astype(dtype={'District':int})\n",
    "    # result: incidents in district under analysis\n",
    "    data_inc_d07 = data_inc_d07[data_inc_d07['District']==7].reset_index(drop=True)\n",
    "    data_inc_d07.to_csv(dest_path+'/'+child.name[:-4]+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# incidents data reading\n",
    "incdnt_file_name = '../data/PeMS/Incidents/raw/all_text_chp_incident_day_2017_10_11.txt'\n",
    "inc_header = ['IncidentID', 'CC_Code', 'Incident_No', 'Timestamp', 'Description', 'Location', 'Area', 'Zoom_Map', 'TBxy', 'Latitude', 'Longitude', 'District', 'CountryFIPS_ID', 'CityFIPS_ID', 'Freeway', 'Freeway_direction', 'State_postmile', 'Absolute_postmile', 'Severity', 'Duration', 'Incident_ID', 'Detail_ID', 'Timestamp', 'description']\n",
    "data_inc_d07 = pd.read_csv(incdnt_file_name, sep=',', names=inc_header, parse_dates=[3])\n",
    "data_inc_d07 = (data_inc_d07.dropna(subset=['District']))[data_inc_d07.columns[:-4]]\n",
    "data_inc_d07 = data_inc_d07.astype(dtype={'District':int})\n",
    "# result: incidents in district under analysis\n",
    "data_inc_d07 = data_inc_d07[data_inc_d07['District']==7].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_inc_d07.to_csv('../data/PeMS/Incidents/light/all_text_chp_incident_day_2017_10_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incdnt_det_file_name = '../data/PeMS/Incidents/all_text_chp_incident_det_day_2017_10_11.txt'\n",
    "det_header = ['ID', 'DetID', 'Timestamp', 'Desc']\n",
    "data_inc_det_d07 = pd.read_csv(incdnt_det_file_name, sep=',', names=det_header, parse_dates=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_inc_det_d07.to_csv('../data/PeMS/Incidents/light/all_text_chp_incident_det_day_2017_10_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_path = '../data/PeMS/Series/raw'\n",
    "dest_path = '../data/PeMS/Series/script_test'\n",
    "pth = Path(raw_path)\n",
    "for child in pth.iterdir():\n",
    "    # incidents data reading\n",
    "    header_srs = ['Timestamp', 'Station','District', 'Freeway', 'Direction of Travel', 'Lane Type', 'Station Length',\n",
    "          'Samples', '% Observed', 'Total Flow', 'Avg Occupancy', 'Avg Speed', \n",
    "          'Lane 1 Samples', 'Lane 1 Flow', 'Lane 1 Avg Occ', 'Lane 1 Avg Speed', 'Lane 1 Observed',\n",
    "          'Lane 2 Samples', 'Lane 2 Flow', 'Lane 2 Avg Occ', 'Lane 2 Avg Speed', 'Lane 2 Observed',\n",
    "          'Lane 3 Samples', 'Lane 3 Flow', 'Lane 3 Avg Occ', 'Lane 3 Avg Speed', 'Lane 3 Observed',\n",
    "          'Lane 4 Samples', 'Lane 4 Flow', 'Lane 4 Avg Occ', 'Lane 4 Avg Speed', 'Lane 4 Observed',\n",
    "          'Lane 5 Samples', 'Lane 5 Flow', 'Lane 5 Avg Occ', 'Lane 5 Avg Speed', 'Lane 5 Observed',\n",
    "          'Lane 6 Samples', 'Lane 6 Flow', 'Lane 6 Avg Occ', 'Lane 6 Avg Speed', 'Lane 6 Observed',\n",
    "          'Lane 7 Samples', 'Lane 7 Flow', 'Lane 7 Avg Occ', 'Lane 7 Avg Speed', 'Lane 7 Observed',\n",
    "          'Lane 8 Samples', 'Lane 8 Flow', 'Lane 8 Avg Occ', 'Lane 8 Avg Speed', 'Lane 8 Observed']\n",
    "\n",
    "    srs_file_name = child.name\n",
    "    data_srs_no_null = pd.read_csv(raw_path+'/'+srs_file_name, sep=',', names=header_srs, parse_dates=[0])\n",
    "    data_srs_no_null = data_srs_no_null[data_srs_no_null.columns[:-40]]\n",
    "    data_srs_no_null = data_srs_no_null.dropna(subset=['Avg Speed']).reset_index(drop=True)\n",
    "    data_srs_no_null.to_csv(dest_path+'/'+child.name[:-4]+'.csv', index=False)\n",
    "    #smoothing\n",
    "    data_srs_smoothed = data_srs_no_null[data_srs_no_null.columns[:16]].copy()\n",
    "    srs_for_smoothing_gb = data_srs_smoothed.groupby(by=['Station'])\n",
    "    j=0\n",
    "    for i, item in srs_for_smoothing_gb:\n",
    "    #     print(item['Avg Speed'].rolling(5).mean())\n",
    "    #     station = item.Station[0]\n",
    "        data_srs_smoothed.loc[item.index, ('Avg Speed')] = item['Avg Speed'].rolling(5).mean()\n",
    "    #     j += 1\n",
    "    #     if j==2:\n",
    "    #         break\n",
    "    data_srs_smoothed = data_srs_smoothed.dropna(subset=['Avg Speed'])\n",
    "    data_srs_smoothed.to_csv(dest_path+'/smoothed/'+child.name[:-4]+'.csv', index=False)\n",
    "    \n",
    "del srs_for_smoothing_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# traffic flow data reading\n",
    "header_srs = ['Timestamp', 'Station','District', 'Freeway', 'Direction of Travel', 'Lane Type', 'Station Length',\n",
    "          'Samples', '% Observed', 'Total Flow', 'Avg Occupancy', 'Avg Speed', \n",
    "          'Lane 1 Samples', 'Lane 1 Flow', 'Lane 1 Avg Occ', 'Lane 1 Avg Speed', 'Lane 1 Observed',\n",
    "          'Lane 2 Samples', 'Lane 2 Flow', 'Lane 2 Avg Occ', 'Lane 2 Avg Speed', 'Lane 2 Observed',\n",
    "          'Lane 3 Samples', 'Lane 3 Flow', 'Lane 3 Avg Occ', 'Lane 3 Avg Speed', 'Lane 3 Observed',\n",
    "          'Lane 4 Samples', 'Lane 4 Flow', 'Lane 4 Avg Occ', 'Lane 4 Avg Speed', 'Lane 4 Observed',\n",
    "          'Lane 5 Samples', 'Lane 5 Flow', 'Lane 5 Avg Occ', 'Lane 5 Avg Speed', 'Lane 5 Observed',\n",
    "          'Lane 6 Samples', 'Lane 6 Flow', 'Lane 6 Avg Occ', 'Lane 6 Avg Speed', 'Lane 6 Observed',\n",
    "          'Lane 7 Samples', 'Lane 7 Flow', 'Lane 7 Avg Occ', 'Lane 7 Avg Speed', 'Lane 7 Observed',\n",
    "          'Lane 8 Samples', 'Lane 8 Flow', 'Lane 8 Avg Occ', 'Lane 8 Avg Speed', 'Lane 8 Observed']\n",
    "\n",
    "srs_file_name = '../data/PeMS/Series/d07_text_station_5min_2017_10_11.txt'\n",
    "data_srs_no_null = pd.read_csv(srs_file_name, sep=',', names=header_srs, parse_dates=[0])\n",
    "data_srs_no_null = data_srs_no_null[data_srs_no_null.columns[:-40]]\n",
    "data_srs_no_null = data_srs_no_null.dropna(subset=['Avg Speed']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_srs_no_null.to_csv('../data/PeMS/Series/light/d07_text_station_5min_2017_10_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_srs_smoothed = data_srs_no_null[data_srs_no_null.columns[:16]].copy()\n",
    "srs_for_smoothing_gb = data_srs_smoothed.groupby(by=['Station'])\n",
    "j=0\n",
    "for i, item in srs_for_smoothing_gb:\n",
    "#     print(item['Avg Speed'].rolling(5).mean())\n",
    "#     station = item.Station[0]\n",
    "    data_srs_smoothed.loc[item.index, ('Avg Speed')] = item['Avg Speed'].rolling(5).mean()\n",
    "#     j += 1\n",
    "#     if j==2:\n",
    "#         break\n",
    "data_srs_smoothed = data_srs_smoothed.dropna(subset=['Avg Speed'])\n",
    "del srs_for_smoothing_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_srs_smoothed.to_csv('../data/PeMS/Series/smoothed/d07_text_station_5min_2017_10_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_stations = '../data/PeMS/Stations/d07_text_meta_2017_09_20.txt'\n",
    "header_stations = ['ID', 'Freeway', 'Freeway dir', 'Country', 'City', 'State Postmile', 'Abs Postmile', \n",
    "          'Latitude', 'Longitude', 'Length', 'Type', 'Lanes', 'Name',\n",
    "          'User ID1', 'User ID2', 'User ID3', 'User ID4']\n",
    "stations_active = pd.read_csv(file_stations, sep='\\t')\n",
    "stations_active = stations_active.astype({'Latitude':float, 'Longitude':float})\n",
    "stations_active = stations_active.dropna(subset=['Latitude', 'Longitude']).reset_index(drop=True)\n",
    "# result: non-empty speed data series  only, stations which provide these data\n",
    "stations_active = stations_active[stations_active['ID'].isin(data_srs_no_null['Station'].unique())].reset_index(drop=True)\n",
    "stations_active = stations_active.sort_values('Lanes', ascending=False).drop_duplicates(subset=['Latitude', 'Longitude'], keep='first').sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations_active.to_csv('../data/PeMS/Stations/light/d07_text_meta_2017_09_20_active.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# incidents week before data reading\n",
    "incdnt_file_name = '../data/PeMS/Incidents/all_text_chp_incident_day_2017_10_04.txt'\n",
    "data_inc_04_d07 = pd.read_csv(incdnt_file_name, sep=',', names=inc_header, parse_dates=[3])\n",
    "data_inc_04_d07 = (data_inc_04_d07.dropna(subset=['District']))[data_inc_04_d07.columns[:-4]]\n",
    "data_inc_04_d07 = data_inc_04_d07.astype(dtype={'District':int})\n",
    "# result: incidents in district under analysis\n",
    "data_inc_04_d07 = data_inc_04_d07[data_inc_04_d07['District']==7].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_inc_04_d07.to_csv('../data/PeMS/Incidents/light/all_text_chp_incident_day_2017_10_04.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# traffic week b4 flow data reading\n",
    "srs_file_name = '../data/PeMS/Series/d07_text_station_5min_2017_10_04.txt'\n",
    "data_srs_no_null_04 = pd.read_csv(srs_file_name, sep=',', names=header_srs, parse_dates=[0])\n",
    "data_srs_no_null_04 = data_srs_no_null_04[data_srs_no_null_04.columns[:-40]]\n",
    "# result: non-empty speed data series  only, stations which provide these data\n",
    "data_srs_no_null_04 = data_srs_no_null_04.dropna(subset=['Avg Speed']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_srs_no_null_04.to_csv('../data/PeMS/Series/light/d07_text_station_5min_2017_10_04.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
